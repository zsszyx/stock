#!/usr/bin/env python3
"""
è‚¡ç¥¨ç­–ç•¥å›æµ‹ä¸»ç¨‹åº
"""
import sys
import os
import time
import json
import argparse
from datetime import datetime, timedelta
import pandas as pd
import numpy as np

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„ï¼Œç¡®ä¿èƒ½æ‰¾åˆ°stockæ¨¡å—
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from stock.database.factory import RepositoryFactory
from stock.config import settings
from stock.data_context.context import DailyContext
from stock.data_context.concept_context_v2 import ConceptContext
from stock.selector.funnel import (
    FunnelSelector, 
    InitialUniverseStep, 
    ConceptRankingStep, 
    LiquidityFilterStep, 
    FinalSelectionStep
)
from stock.backtest.bt_backtester import BTBacktester, KSPPandasData
from stock.backtest.ksp_strategy import KSPStrategy
import backtrader as bt

def run_backtest(args=None):
    """
    è¿è¡Œå›æµ‹ä¸»å‡½æ•°
    args: argparse.Namespace or object with attributes
    """
    print("="*70)
    print("ğŸš€ è‚¡ç¥¨ç­–ç•¥å›æµ‹ç³»ç»Ÿå¯åŠ¨ (Funnel Mode)")
    print("="*70)

    # 1. å‚æ•°å¤„ç†
    start_date = getattr(args, 'start', "2025-01-01")
    if not start_date: start_date = "2025-01-01"
    
    end_date = datetime.now().strftime('%Y-%m-%d')
    # å¦‚æœargsæœ‰endå±æ€§ä¸”ä¸ä¸ºç©ºï¼Œåˆ™ä½¿ç”¨
    if hasattr(args, 'end') and args.end:
        end_date = args.end
        
    slots = getattr(args, 'slots', 9)
    cash = getattr(args, 'cash', 1000000.0)
    top_concepts = getattr(args, 'top_concepts', 3)
    top_stocks = getattr(args, 'top_stocks', 3)
    sell_rank = getattr(args, 'sell_rank', 300)
    tp = getattr(args, 'tp', 0.10)
    sl = getattr(args, 'sl', -0.02)
    period = getattr(args, 'period', 5) # ksp_period
    min_amount = 50000000 # æ¢å¤è‡³ 5000 ä¸‡

    print(f"âš™ï¸  é…ç½®: èµ„é‡‘={cash:,.0f}, ä»“ä½={slots}, æ­¢ç›ˆ={tp:.0%}, æ­¢æŸ={sl:.0%}, å–å‡ºæ’å>{sell_rank}")
    print(f"ğŸ“… å‘¨æœŸ: {start_date} ~ {end_date}")

    repo = RepositoryFactory.get_clickhouse_repo()

    # 2. è®¡ç®—åŠ è½½æ•°æ®çš„èµ·å§‹æ—¶é—´ (start_date - 120å¤©)
    start_dt = datetime.strptime(start_date, '%Y-%m-%d')
    load_start_dt = start_dt - timedelta(days=120)
    load_start_date = load_start_dt.strftime('%Y-%m-%d')
    
    # è¯Šæ–­ ClickHouse è¿æ¥ä¸æ•°æ®é‡ (æ›´é²æ£’çš„å®ç°)
    print(f"ğŸ” æ­£åœ¨è¯Šæ–­ ClickHouse æ•°æ®æº...")
    try:
        db_res = repo.query("SELECT database()")
        db_name = db_res.iloc[0,0] if not db_res.empty else "UNKNOWN"
        
        count_res = repo.query(f"SELECT count(*) FROM {settings.TABLE_DAILY}")
        row_count = count_res.iloc[0,0] if not count_res.empty else 0
        
        range_res = repo.query(f"SELECT min(date), max(date) FROM {settings.TABLE_DAILY}")
        min_date = range_res.iloc[0,0] if not range_res.empty else "N/A"
        max_date = range_res.iloc[0,1] if not range_res.empty else "N/A"
        
        print(f"   ğŸ“‚ å½“å‰æ•°æ®åº“: {db_name}, è¡¨: {settings.TABLE_DAILY}")
        print(f"   ğŸ“Š å­˜é‡æ•°æ®: {row_count:,} è¡Œ, èŒƒå›´: {min_date} ~ {max_date}")
        
        if row_count == 0:
            print("âš ï¸ è­¦å‘Š: æ•°æ®åº“ä¸­æ²¡æœ‰è¡Œæƒ…æ•°æ®ï¼Œè¯·æ£€æŸ¥æ•°æ®åŒæ­¥çŠ¶æ€ã€‚")
            repo.close()
            return
    except Exception as e:
        print(f"âš ï¸ è¯Šæ–­è¿‡ç¨‹å‡ºé”™: {e}")

    # 3. åŠ è½½è¡Œæƒ…æ•°æ®
    print(f"\nğŸ“Š æ­£åœ¨è¯·æ±‚æŸ¥è¯¢ (from {load_start_date})...")
    start_t = time.time()
    
    sql = f"SELECT * FROM {settings.TABLE_DAILY} WHERE date >= '{load_start_date}' ORDER BY date ASC"
    daily_df = repo.query(sql)
    
    if daily_df.empty:
        print(f"âŒ é”™è¯¯: SQL æŸ¥è¯¢è¿”å›ç©ºã€‚SQL: {sql}")
        repo.close()
        return

    # å»é‡
    daily_df = daily_df.drop_duplicates(subset=['date', 'code'], keep='last')
    print(f"ğŸš€ æ•°æ®åŠ è½½å®Œæˆ: {time.time()-start_t:.1f}s, {len(daily_df):,} è¡Œ")

    print("\nğŸ“ˆ åŠ è½½åŸºå‡†æ•°æ® (ä¸Šè¯æŒ‡æ•°)...")
    benchmark_df = repo.query(f"""
        SELECT date, close FROM {settings.TABLE_BENCHMARK}
        WHERE code = 'sh.000001' AND date >= '{start_date}' AND date <= '{end_date}'
        ORDER BY date ASC
    """)
    if benchmark_df.empty:
        print("âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°åŸºå‡†æ•°æ®ï¼Œå°†ä¸æ˜¾ç¤ºåŸºå‡†å¯¹æ¯”")
        benchmark_df = None

    # 3. åˆå§‹åŒ–ç­–ç•¥ (ä½¿ç”¨æ–°çš„ Funnel æ¶æ„)
    print("\nğŸ”§ åˆå§‹åŒ–ç­–ç•¥ä¸Šä¸‹æ–‡ (Funnel Pipeline)...")
    daily_ctx = DailyContext(daily_df=daily_df)
    concept_ctx = ConceptContext(repo=repo)
    
    # æ„å»ºæ¼æ–—æ­¥éª¤
    steps = [
        InitialUniverseStep(),                                  # Step 0: åŸºç¡€è¿‡æ»¤
        ConceptRankingStep(top_n=top_concepts),                 # Step 1: æ¦‚å¿µä¼˜é€‰
        LiquidityFilterStep(min_amount=min_amount),             # Step 2: æµåŠ¨æ€§è¿‡æ»¤
        # ç§»é™¤æ³¢åŠ¨ç‡ç­›é€‰
        FinalSelectionStep(top_n_per_concept=top_stocks)        # Step 3: æœ€ç»ˆ KSP ç²¾é€‰
    ]
    
    strategy_obj = FunnelSelector(daily_ctx, concept_ctx, steps)

    # 4. æ‰§è¡Œå›æµ‹
    print("\n" + "="*70)
    print("ğŸ¯ å¼€å§‹æ‰§è¡Œå›æµ‹")
    print("="*70)

    # åˆå§‹åŒ–æ ¸å¿ƒç­–ç•¥æ¨¡å— (ç­–ç•¥æ¨¡å¼)
    from stock.strategy.ksp_core import KSPCore
    core_strategy = KSPCore(
        selector_obj=strategy_obj,
        slots=slots,
        sell_rank=sell_rank,
        take_profit=tp,
        stop_loss=sl
    )

    # ä½¿ç”¨ KSPStrategy é€‚é…å™¨
    cerebro = bt.Cerebro()
    cerebro.broker.setcash(cash)
    cerebro.broker.setcommission(commission=0.0005)

    # è·å–æ—¥æœŸèŒƒå›´
    all_dates = sorted(daily_df['date'].unique())
    full_idx = pd.to_datetime(all_dates)
    
    # åŠ è½½åŸºå‡†æ•°æ®
    if benchmark_df is not None:
        b_df = benchmark_df.copy()
        if 'date' in b_df.columns:
            b_df['datetime'] = pd.to_datetime(b_df['date'])
            b_df = b_df.set_index('datetime').reindex(full_idx).ffill().bfill()
            bm_feed = bt.feeds.PandasData(dataname=b_df, name='_master_clock_', plot=False)
            cerebro.adddata(bm_feed)
    else:
        dummy_df = pd.DataFrame(index=full_idx, data={'close': 1.0})
        cerebro.adddata(bt.feeds.PandasData(dataname=dummy_df, name='_master_clock_', plot=False))

    # é¢„è¿‡æ»¤å€™é€‰è‚¡ç¥¨
    candidate_codes = set()
    for d_str in all_dates:
        dt = datetime.strptime(d_str, '%Y-%m-%d')
        if dt >= datetime.strptime(start_date, '%Y-%m-%d'):
            try:
                selection = strategy_obj.select(dt)
                if selection:
                    candidate_codes.update(selection)
            except:
                pass
    
    print(f"Total unique candidates to load: {len(candidate_codes)}")

    # åŠ è½½ä¸ªè‚¡æ•°æ®
    df_all = daily_df[daily_df['code'].isin(candidate_codes)].copy()
    df_all['datetime'] = pd.to_datetime(df_all['date'])
    df_all = df_all.set_index(['code', 'datetime']).sort_index()
    
    for code in candidate_codes:
        try:
            if code not in df_all.index.get_level_values(0):
                continue
            code_df = df_all.loc[(code, slice(None)), :].reset_index(level=0, drop=True)
            if code_df.empty:
                continue
            
            aligned_df = code_df.reindex(full_idx)
            fill_cols = ['open', 'high', 'low', 'close', 'poc', 'ksp_sum_5d_rank', 'list_days']
            for col in fill_cols:
                if col in aligned_df.columns:
                    if col in ['open', 'high', 'low', 'close', 'poc']:
                        aligned_df.loc[aligned_df[col] <= 0.01, col] = np.nan
                    aligned_df[col] = aligned_df[col].ffill().bfill()
            
            aligned_df['volume'] = aligned_df['volume'].fillna(0)
            if 'list_days' not in aligned_df.columns:
                aligned_df['list_days'] = 0
            aligned_df['list_days'] = aligned_df['list_days'].fillna(0)
            
            if aligned_df['close'].isna().all():
                continue
            
            data = KSPPandasData(dataname=aligned_df, name=code, plot=False)
            cerebro.adddata(data)
        except:
            continue

    # æ·»åŠ ç­–ç•¥é€‚é…å™¨
    cerebro.addstrategy(
        KSPStrategy,
        core_strategy=core_strategy,
        slots=slots,
        log_file='backtest_detailed_log.json'
    )

    # æ·»åŠ åˆ†æå™¨
    cerebro.addanalyzer(bt.analyzers.TimeReturn, _name='returns')
    cerebro.addanalyzer(bt.analyzers.SharpeRatio, _name='sharpe', riskfreerate=0.0, annualize=True)
    cerebro.addanalyzer(bt.analyzers.DrawDown, _name='drawdown')
    cerebro.addanalyzer(bt.analyzers.TradeAnalyzer, _name='trades')

    print("Starting Backtrader execution...")
    results = cerebro.run(runonce=False)
    strat = results[0] if results else None

    print(f"\nâœ… å›æµ‹æ‰§è¡Œå®Œæˆ")

    # 5. ç»“æœåˆ†æä¸ä¿å­˜
    if strat is not None:
        # æ‰“å°æ‘˜è¦
        returns = strat.analyzers.returns.get_analysis()
        sharpe = strat.analyzers.sharpe.get_analysis()
        drawdown = strat.analyzers.drawdown.get_analysis()
        trades = strat.analyzers.trades.get_analysis()
        
        print("\n" + "="*40 + "\n      PROFESSIONAL BACKTEST REPORT      \n" + "="*40)
        print(f"Final Value:     {strat.broker.getvalue():,.2f}")
        print(f"Total Return:    {(strat.broker.getvalue()/cash - 1)*100:.2f}%")
        print(f"Max Drawdown:    {drawdown.max.drawdown:.2f}%")
        s_val = sharpe.get('sharperatio', 0)
        print(f"Sharpe Ratio:    {s_val if s_val is not None else 0:.2f}")
        
        if 'total' in trades:
            total = trades.total.total
            print(f"Total Trades:    {total}")
            if total > 0:
                print(f"Win Rate:        {(trades.won.total/total)*100:.2f}%")
        print("="*40)
        
        # åˆ†æè¯¦ç»†æ—¥å¿—
        analyze_logs()
    
    repo.close()

def analyze_logs(log_file='backtest_detailed_log.json'):
    """åˆ†æç­–ç•¥ç”Ÿæˆçš„è¯¦ç»†æ—¥å¿—"""
    print("\n" + "="*70)
    print("ğŸ“ è¯¦ç»†äº¤æ˜“æ—¥å¿—åˆ†æ")
    print("="*70)

    if not os.path.exists(log_file):
        print("âš ï¸  æœªæ‰¾åˆ°æ—¥å¿—æ–‡ä»¶")
        return

    try:
        with open(log_file, 'r') as f:
            log_data = json.load(f)

        print(f"æ€»äº¤æ˜“è®°å½•: {len(log_data.get('trade_records', []))}")
        
        # ç”ŸæˆCSVæŠ¥è¡¨
        trades = log_data.get('trade_records', [])
        if trades:
            df_trades = pd.DataFrame(trades)
            df_trades.to_csv('backtest_trades.csv', index=False)
            print(f"âœ… äº¤æ˜“æ˜ç»†å·²ä¿å­˜: backtest_trades.csv")
            
            # ç®€å•ç»Ÿè®¡
            buys = df_trades[df_trades['action']=='BUY']
            sells = df_trades[df_trades['action']=='SELL']
            print(f"   ä¹°å…¥: {len(buys)}, å–å‡º: {len(sells)}")
            
        daily = log_data.get('daily_records', [])
        if daily:
            df_daily = pd.DataFrame(daily)
            df_daily.to_csv('backtest_daily.csv', index=False)
            print(f"âœ… æ¯æ—¥å‡€å€¼å·²ä¿å­˜: backtest_daily.csv")

    except Exception as e:
        print(f"âŒ æ—¥å¿—åˆ†æå‡ºé”™: {e}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="è¿è¡Œè‚¡ç¥¨ç­–ç•¥å›æµ‹")
    parser.add_argument("--start", type=str, default="2025-01-01", help="å¼€å§‹æ—¥æœŸ")
    parser.add_argument("--end", type=str, default=None, help="ç»“æŸæ—¥æœŸ")
    parser.add_argument("--cash", type=float, default=1000000.0, help="åˆå§‹èµ„é‡‘")
    parser.add_argument("--slots", type=int, default=9, help="æœ€å¤§æŒä»“æ•°")
    parser.add_argument("--top-concepts", type=int, default=3, help="é€‰ä¸­æ¦‚å¿µæ•°")
    parser.add_argument("--top-stocks", type=int, default=3, help="æ¯ä¸ªæ¦‚å¿µé€‰è‚¡æ•°")
    parser.add_argument("--sell-rank", type=int, default=400, help="å–å‡ºæ’åé˜ˆå€¼")
    parser.add_argument("--tp", type=float, default=0.10, help="æ­¢ç›ˆæ¯”ä¾‹")
    parser.add_argument("--sl", type=float, default=-0.02, help="æ­¢æŸæ¯”ä¾‹")
    parser.add_argument("--period", type=int, default=5, help="KSPå‘¨æœŸ")
    
    args = parser.parse_args()
    run_backtest(args)
