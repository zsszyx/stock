import os
import sys
import pandas as pd
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from stock.database.factory import RepositoryFactory
from stock.data_context.context import DailyContext
from stock.config import settings

def refresh_all_factors():
    repo = RepositoryFactory.get_clickhouse_repo()
    
    print("ğŸ“¥ Loading all data from daily_kline...")
    df = repo.query(f"SELECT * FROM {settings.TABLE_DAILY}")
    
    if df.empty:
        print("âŒ No data found in daily_kline.")
        return

    print(f"ğŸ“Š Loaded {len(df)} records. Processing factors and GLOBAL ranks...")
    
    # æŒ‰ç…§ä»£ç å’Œæ—¥æœŸæ’åºï¼Œç¡®ä¿æ»šåŠ¨è®¡ç®—æ­£ç¡®
    df = df.sort_values(['code', 'date'])
    
    # ç›´æ¥åœ¨å…¨é‡ DataFrame ä¸Šè°ƒç”¨æ´¾ç”Ÿå› å­è®¡ç®—é€»è¾‘
    # æ³¨æ„ï¼šDailyContext._add_derived_factors å†…éƒ¨ä¼šè°ƒç”¨ KSPFactorEngine.add_rolling_factors
    # è€Œ add_rolling_factors åŒ…å«æ­£ç¡®çš„ groupby('code') å’Œ groupby('date') é€»è¾‘
    updated_df = DailyContext._add_derived_factors(df)

    print("ğŸ”„ Preparing for upload...")
    # ç¡®ä¿åˆ—é¡ºåºä¸æ•°æ®åº“ä¸€è‡´
    final_df = updated_df[DailyContext.COLUMNS]
    
    # å¼ºåˆ¶è½¬æ¢æ•´æ•°åˆ—ï¼Œé¿å… 1.0 è¿™ç§æ ¼å¼å¯¼è‡´ ClickHouse æ— æ³•è§£æ Int32/Int64
    int_cols = ['volume', 'ksp_rank', 'ksp_sum_14d_rank', 'ksp_sum_10d_rank', 'ksp_sum_7d_rank', 'ksp_sum_5d_rank', 'list_days']
    for col in int_cols:
        if col in final_df.columns:
            final_df[col] = final_df[col].fillna(0).astype(int)

    print(f"ğŸ“¤ Inserting {len(final_df)} updated records back to {settings.TABLE_DAILY}...")
    repo.insert_df(final_df, settings.TABLE_DAILY)
    
    print("âœ… All factors and global ranks refreshed successfully.")
    print("ğŸ§¹ Optimizing table...")
    repo.optimize_table(settings.TABLE_DAILY)
    print("âœ¨ Done.")

if __name__ == "__main__":
    refresh_all_factors()
