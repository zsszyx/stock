import pandas as pd
from typing import List, Optional
from stock.tasks.base import BaseTask
from stock.database.factory import RepositoryFactory
from stock.config import settings
from stock.data_context.context import DailyContext

class DailyAggregationTask(BaseTask):
    """
    è§£è€¦åçš„æ—¥çº¿èšåˆä»»åŠ¡ï¼š
    èŒè´£ï¼šè¯»å– ClickHouse ä¸­çš„åˆ†é’Ÿçº¿ -> èšåˆè®¡ç®—å› å­ -> å†™å…¥æ—¥çº¿è¡¨
    """
    def __init__(self, chunk_size: int = 5):
        super().__init__("DailyAggregationTask")
        self.chunk_size = chunk_size
        self.repo = RepositoryFactory.get_clickhouse_repo()

    def run(self, start_date: str, end_date: str, clear_target: bool = False):
        self.log_progress(f"ğŸš€ å¼€å§‹èšåˆä»»åŠ¡: {start_date} -> {end_date} (æ¸…ç†ç›®æ ‡={clear_target})")
        
        # ReplacingMergeTree naturally handles duplicates on (code, date). 
        # Manual DELETE is risky due to asynchronicity.
        
        # 1. è·å–åˆ†é’Ÿçº¿è¡¨ä¸­å­˜åœ¨çš„æ—¥æœŸ
        query_dates = f"SELECT DISTINCT date FROM {settings.TABLE_MIN5} WHERE date >= '{start_date}' AND date <= '{end_date}' ORDER BY date ASC"
        available_dates = self.repo.query(query_dates)['date'].tolist()
        
        if not available_dates:
            self.log_progress("âš ï¸  æœªåœ¨ 5 åˆ†é’Ÿçº¿è¡¨ä¸­æ‰¾åˆ°æŒ‡å®šèŒƒå›´çš„æ•°æ®ã€‚")
            return

        self.log_progress(f"ğŸ“Š å‘ç° {len(available_dates)} å¤©å¾…å¤„ç†æ•°æ®ï¼Œå¼€å§‹åˆ†å—å¤„ç†...")

        for i in range(0, len(available_dates), self.chunk_size):
            chunk = available_dates[i : i + self.chunk_size]
            self._process_chunk(chunk)

        # 2. ç‰©ç†å»é‡ä¼˜åŒ–
        self.repo.optimize_table(settings.TABLE_DAILY)
        self.log_progress("ğŸ æ—¥çº¿èšåˆä¸å› å­è®¡ç®—å®Œæˆã€‚")
        
        # 3. è‡ªåŠ¨å¥åº·è‡ªæ£€
        from stock.utils.health_check import DataHealthMonitor
        monitor = DataHealthMonitor(repo=self.repo)
        monitor.validate_or_raise()

    def _process_chunk(self, dates: List[str]):
        try:
            start, end = dates[0], dates[-1]
            # ä»åˆ†é’Ÿçº¿è¡¨è¯»å–å·²è¡¥å…¨çš„æ•°æ® (åªè¯»å–å¿…è¦åˆ—ä»¥å‡å°‘å†…å­˜å’ŒIOæ¶ˆè€—)
            cols = "date, time, code, open, high, low, close, volume, amount"
            query = f"SELECT {cols} FROM {settings.TABLE_MIN5} WHERE date >= '{start}' AND date <= '{end}'"
            df_min5 = self.repo.query(query)
            
            if df_min5.empty: return
                
            # åˆ©ç”¨ä¼˜åŒ–åçš„ DailyContext è¿›è¡Œé«˜æ€§èƒ½èšåˆ
            df_daily = DailyContext.from_min5(df_min5)
            
            # å†™å…¥æ—¥çº¿è¡¨
            self.repo.insert_df(df_daily, settings.TABLE_DAILY)
            self.log_progress(f"  âœ… å·²å®Œæˆå—: {start} è‡³ {end} ({len(df_daily)} è¡Œ)")
        except Exception as e:
            self.log_error(f"âŒ èšåˆå— {dates[0]} å¤±è´¥", e)

    def close(self):
        self.repo.close()
